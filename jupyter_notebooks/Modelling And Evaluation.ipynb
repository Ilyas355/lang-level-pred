{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebf79c1",
   "metadata": {},
   "source": [
    "# 05. Modelling and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac5cb3",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The purpose of this notebook is to train, evaluate, and interpret machine learning models that predict **CEFR levels** based on learners’ language proficiency scores and engineered features. Specifically, we aim to:\n",
    "\n",
    "- Train classification models using the processed dataset (numeric + categorical engineered features).  \n",
    "- Compare model performance across multiple algorithms (e.g., Logistic Regression, Random Forest, Gradient Boosting).  \n",
    "- Evaluate models using accuracy, precision, recall, F1-score, and confusion matrices to assess classification reliability.  \n",
    "- Select the best-performing model for deployment and future integration into a personalized recommendation system.  \n",
    "- Save the trained model and evaluation results for reproducibility and downstream use.  \n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- **Processed dataset**: `data/processed/features.csv`  \n",
    "  - Includes original skill scores, engineered features (e.g., strongest/weakest skill, profile type), and encoded CEFR target variable.  \n",
    "- **Feature matrix (X)**: Scaled numeric features + encoded categorical engineered features.  \n",
    "- **Target vector (y)**: Encoded CEFR levels (A1–C2).  \n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Trained machine learning models (baseline + advanced).  \n",
    "- Evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix).  \n",
    "- Visualizations of model performance.  \n",
    "- Final selected model, serialized (e.g., `model.joblib`) for reuse.  \n",
    "- Documentation of why the chosen model best supports the **business goal** of automatic learner placement.  \n",
    "\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "This stage directly addresses the **business requirement**: predicting learners’ CEFR levels to enable **automatic placement** and **personalized learning recommendations**.  \n",
    "While the model outputs only the predicted CEFR level, the engineered features (skill strengths, weaknesses, balance profiles) provide the contextual insights needed for tailored feedback.  \n",
    "By rigorously evaluating different models and selecting the best one, we ensure predictions are not only accurate but also interpretable, reliable, and suitable for real-world integration into an adaptive learning platform.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801c026",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb9b54",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7500c31",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849c2560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8bbf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0feac2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd7968",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "- seaborn: creating attractive and informative statistical graphics from datasets\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1654478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.1\n",
      "NumPy version: 2.3.1\n",
      "matplotlib version: 3.10.5\n",
      "seaborn version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97126b98",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data/clean folder and what folder we are currently in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b6d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\processed:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['features.csv', 'target.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/processed\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f631987",
   "metadata": {},
   "source": [
    "### 3. Load Processed Data\n",
    "\n",
    "In this step, we will load the processed dataset that was prepared in the Feature Engineering Notebook.  \n",
    "The data has been saved in two separate files:\n",
    "\n",
    "- `features.csv` → contains the engineered and scaled features.  \n",
    "- `target.csv` → contains the encoded CEFR levels.  \n",
    "\n",
    "We will:\n",
    "- Load both files.  \n",
    "- Inspect their structure (rows, columns, datatypes).  \n",
    "- Confirm they align correctly (same number of rows).  \n",
    "- Prepare them as `X` (features) and `y` (target) for model training.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fcd570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1004, 12)\n",
      "Target shape: (1004,)\n",
      "\n",
      "Feature columns:\n",
      " ['speaking_score', 'reading_score', 'listening_score', 'writing_score', 'strongest_skill', 'weakest_skill', 'second_weakest_skill', 'skill_std', 'strength_weakness_gap', 'productive_receptive_ratio', 'avg_score', 'learning_profile']\n",
      "\n",
      "Target preview:\n",
      " 0    0\n",
      "1    4\n",
      "2    2\n",
      "3    2\n",
      "4    3\n",
      "Name: cefr_encoded, dtype: int64\n",
      "✅ Features and target aligned correctly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load processed features and target\n",
    "X = pd.read_csv(\"data/processed/features.csv\")\n",
    "y = pd.read_csv(\"data/processed/target.csv\").squeeze()  # convert to Series\n",
    "\n",
    "# Inspect shapes\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFeature columns:\\n\", X.columns.tolist())\n",
    "print(\"\\nTarget preview:\\n\", y.head())\n",
    "\n",
    "# Validate alignment\n",
    "assert X.shape[0] == y.shape[0], \"❌ Row mismatch between features and target!\"\n",
    "print(\"✅ Features and target aligned correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
