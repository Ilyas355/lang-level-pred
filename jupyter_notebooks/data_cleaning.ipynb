{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2d5caa",
   "metadata": {},
   "source": [
    "# 02. Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2484af",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Remove duplicates and handle missing values using appropriate, documented strategies.\n",
    "- Standardise data formats and fix inconsistent data types.\n",
    "- Produce a **clean, analysis-ready dataset** without introducing target leakage.\n",
    "\n",
    "## Inputs\n",
    "- Raw dataset from the Data Collection phase (e.g., `data/raw/lang_proficiency_results.csv` or similar).\n",
    "\n",
    "## Outputs\n",
    "- Cleaned dataset saved to `data/clean/cleaned_lang_proficiency_results.csv`.\n",
    "- Summary of **before/after** data quality (row count, duplicates removed, missingness by column).\n",
    "- A brief **change log** documenting cleaning decisions and transformations (e.g., imputation rules, dtype fixes).\n",
    "\n",
    "## Additional Information\n",
    "- All cleaning operations are reproducible and justified (with code + rationale).\n",
    "- Backups of raw data are preserved; no edits are made to `data/raw/`.\n",
    "- Outliers and missing values are handled with domain-appropriate methods and clearly documented.\n",
    "- Cleaning focuses on data quality; **feature creation and leakage mitigation** are handled later in the Feature Engineering notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf875c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f144df6",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262d735",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6647d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd36c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a5bfd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c06e13",
   "metadata": {},
   "source": [
    "# Data loading and basic exploration\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f40cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.1\n",
      "NumPy version: 2.3.1\n",
      "matplotlib version: 3.10.5\n"
     ]
    }
   ],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd1233",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data folder and what folder we are currently in. \n",
    "- Subsequently we aren't in the right folder so the current path is set to the parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a71e9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\raw:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lang_proficiency_results_raw.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/raw\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a5f3d",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This code loads the dataset that is then displayed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db14c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = Path(\"data/raw/lang_proficiency_results_raw.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a875771",
   "metadata": {},
   "source": [
    "## Identifying problems in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d75326",
   "metadata": {},
   "source": [
    "### Check Missing Values in Dataset\n",
    "This code analyzes and displays missing values in our bulldozer dataset:\n",
    "- Uses pandas' isna() function to identify missing values\n",
    "- Counts total missing values per column using sum()\n",
    "- Sorts results in descending order to highlight columns with most missing data\n",
    "\n",
    "Previously this showed multiple missing values in some of the columns but i mistakenly ran it again after fixing the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8735828e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_cefr       16\n",
       "listening_score    16\n",
       "speaking_score     14\n",
       "reading_score       9\n",
       "writing_score       8\n",
       "user_id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130a938",
   "metadata": {},
   "source": [
    "### Check for Duplicates\n",
    "This code checks if any duplicates exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6885bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>overall_cefr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>508</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>819</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>453</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>369</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>243</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>930</td>\n",
       "      <td>82.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>263</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>811</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>319</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>50</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  speaking_score  reading_score  listening_score  writing_score  \\\n",
       "1000      508            32.0           31.0             35.0           39.0   \n",
       "1001      819            57.0           55.0             58.0           56.0   \n",
       "1002      453            61.0           59.0             57.0           70.0   \n",
       "1003      369            53.0           55.0             47.0           53.0   \n",
       "1004      243            51.0           47.0             41.0           48.0   \n",
       "1005      930            82.0           72.0             71.0           74.0   \n",
       "1006      263            89.0           91.0             90.0           88.0   \n",
       "1007      811            29.0           40.0             27.0           31.0   \n",
       "1008      319            52.0           50.0             50.0           47.0   \n",
       "1009       50            27.0           32.0             40.0           25.0   \n",
       "\n",
       "     overall_cefr  \n",
       "1000           A1  \n",
       "1001           B1  \n",
       "1002           B1  \n",
       "1003           A2  \n",
       "1004           A2  \n",
       "1005           B2  \n",
       "1006           C1  \n",
       "1007           A1  \n",
       "1008           A2  \n",
       "1009           A1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Count total duplicates\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# View the duplicate rows (if any)\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a6afa",
   "metadata": {},
   "source": [
    "## Check for outliers\n",
    "This code checks the dataset to see if any scores exist outide of the range 100 < x < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "389ced1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaking_score: 0 outliers\n",
      "listening_score: 0 outliers\n",
      "reading_score: 7 outliers\n",
      "writing_score: 0 outliers\n"
     ]
    }
   ],
   "source": [
    "# Check outliers for all score columns\n",
    "score_columns = ['speaking_score', 'listening_score', 'reading_score', 'writing_score']\n",
    "\n",
    "for col in score_columns:\n",
    "   outliers = ((df[col] < 1) | (df[col] > 100)).sum()\n",
    "   print(f\"{col}: {outliers} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f02de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              int64\n",
       "speaking_score     float64\n",
       "reading_score      float64\n",
       "listening_score    float64\n",
       "writing_score      float64\n",
       "overall_cefr        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "286607d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1010 entries, 0 to 1009\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   user_id          1010 non-null   int64  \n",
      " 1   speaking_score   996 non-null    float64\n",
      " 2   reading_score    1001 non-null   float64\n",
      " 3   listening_score  994 non-null    float64\n",
      " 4   writing_score    1002 non-null   float64\n",
      " 5   overall_cefr     994 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 47.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaadbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['listening_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a02e086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['speaking_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6ca3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['writing_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66f9cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['reading_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7404e34",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c378fc0",
   "metadata": {},
   "source": [
    "### Filling Missing CEFR Levels\n",
    "\n",
    "- Some rows in the dataset are missing their overall_cefr value.\n",
    "- The CEFR level is determined by the user’s skill scores (Speaking, Listening, Reading, Writing) \n",
    "- We can infer the missing CEFRs by calculating the average score per row and mapping it to the correct level.\n",
    "\n",
    "We use the scoring thresholds defined in this dataset:\n",
    "\n",
    "| Average Score | CEFR |\n",
    "| ------------- | ---- |\n",
    "| 20–40         | A1   |\n",
    "| 41–55         | A2   |\n",
    "| 56–70         | B1   |\n",
    "| 71–85         | B2   |\n",
    "| 86–92         | C1   |\n",
    "| 93+           | C2   |\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "- If a user has scores (Speaking=72, Reading=74, Listening=70, Writing=71), the row average = 71.75 → this falls in the 71–85 range, so their overall_cefr is assigned as B2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83380e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map average score → CEFR level\n",
    "def assign_cefr(score):\n",
    "    if score <= 40: return \"A1\"\n",
    "    elif score <= 55: return \"A2\"\n",
    "    elif score <= 70: return \"B1\"\n",
    "    elif score <= 85: return \"B2\"\n",
    "    elif score <= 92: return \"C1\"\n",
    "    else: return \"C2\"\n",
    "\n",
    "# Identify rows with missing CEFR\n",
    "mask = df[\"overall_cefr\"].isna()\n",
    "\n",
    "# Compute row averages for those rows (ignoring NaNs in skills)\n",
    "row_means = df.loc[mask, [\"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\"]].mean(axis=1, skipna=True)\n",
    "\n",
    "# Assign CEFR levels\n",
    "df.loc[mask, \"overall_cefr\"] = row_means.apply(assign_cefr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab683b31",
   "metadata": {},
   "source": [
    "#### Verify fix\n",
    "- This code verifies there are no remaining mising values in the overall_cefr column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c5642a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listening_score    16\n",
       "speaking_score     14\n",
       "reading_score       9\n",
       "writing_score       8\n",
       "user_id             0\n",
       "overall_cefr        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95e61d",
   "metadata": {},
   "source": [
    "### Handling Missing Values by Group Mean Imputation\n",
    "\n",
    "In this dataset, each user’s skill scores (Speaking, Listening, Reading, Writing) directly influence their overall CEFR level.\n",
    "If we replaced missing values with a global mean across all CEFR levels, it would distort the relationship between individual skills and the CEFR classification.\n",
    "\n",
    "Instead, we fill missing values using the mean score within the same CEFR group.\n",
    "This way, the imputation reflects the performance range typical of each level.\n",
    "\n",
    "Example:\n",
    "\n",
    "- If a speaking_score is missing for a B2 user:\n",
    "- Collect all B2 users’ speaking scores.\n",
    "- Compute the mean of those scores.\n",
    "- Fill the missing value with this mean.\n",
    "- This preserves the internal consistency of the dataset while ensuring no missing values remain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "755b6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values by CEFR group mean\n",
    "for col in [\"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\"]:\n",
    "    df[col] = df.groupby(\"overall_cefr\")[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed26840",
   "metadata": {},
   "source": [
    "### Verify fix\n",
    "- This code verifies the missing values where successfully addressed and should show no remaining missing values in any cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b0fd9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id            0\n",
       "speaking_score     0\n",
       "reading_score      0\n",
       "listening_score    0\n",
       "writing_score      0\n",
       "overall_cefr       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1623f66",
   "metadata": {},
   "source": [
    "## Fixing Inconsistent Categorical Labels\n",
    "\n",
    "In the dataset, some overall_cefr values appear in lowercase (e.g., \"b2\", \"c2\") while most are uppercase (\"B2\", \"C2\").\n",
    "This inconsistency could cause issues when grouping or filtering by CEFR levels.\n",
    "\n",
    "To standardize the labels, we convert all values in the overall_cefr column to uppercase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e369e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize all CEFR values to ensure consistency\n",
    "df['overall_cefr'] = df['overall_cefr'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb9020",
   "metadata": {},
   "source": [
    "## Round Scores to Integers\n",
    "- Since all scores are percentages, they should be stored as whole numbers.\n",
    "- We round any decimal values to the nearest integer and cast the columns to integer type.\n",
    "- This maintains consistency in the dataset and ensures that all scores are expressed as whole percentage values between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71472ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['speaking_score', 'reading_score', 'listening_score', 'writing_score']] = \\\n",
    "df[['speaking_score', 'reading_score', 'listening_score', 'writing_score']].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aba5dd",
   "metadata": {},
   "source": [
    "### Verify fix \n",
    "- This code gives a brief look at the updated dataset with the now rounded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "979810e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>overall_cefr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>56</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>71</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  speaking_score  reading_score  listening_score  writing_score  \\\n",
       "0         1              26             40               28             33   \n",
       "1         2              91             92               89             87   \n",
       "2         3              61             66               66             57   \n",
       "3         4              65             60               55             55   \n",
       "4         5              77             76               83             78   \n",
       "5         6              58             66               61             56   \n",
       "6         7              50             46               55             52   \n",
       "7         8              78             71               82             81   \n",
       "8         9              45             51               42             49   \n",
       "9        10              64             64               68             56   \n",
       "10       11              53             45               41             53   \n",
       "11       12              35             37               34             36   \n",
       "12       13              42             44               46             49   \n",
       "13       14              54             46               52             48   \n",
       "14       15              67             68               66             70   \n",
       "15       16              33             26               26             32   \n",
       "16       17              68             69               62             61   \n",
       "17       18              84             71               75             73   \n",
       "18       19              64             65               56             58   \n",
       "19       20              87             91               87             90   \n",
       "20       21              73             79               76             82   \n",
       "21       22              87             89               89             86   \n",
       "22       23              85             89               89             90   \n",
       "23       24              64             62               64             59   \n",
       "24       25              40             44               55             46   \n",
       "25       26              55             64               55             66   \n",
       "26       27              99             95               99            100   \n",
       "27       28              97             98              100             98   \n",
       "28       29              58             65               58             59   \n",
       "29       30              41             45               48             48   \n",
       "30       31              67             68               62             63   \n",
       "31       32              65             67               62             58   \n",
       "32       33              99             98               96             97   \n",
       "33       34              43             53               54             49   \n",
       "34       35              90             92               90             89   \n",
       "35       36              28             37               36             40   \n",
       "36       37              71             84               72             79   \n",
       "37       38              54             53               55             48   \n",
       "38       39              34             33               36             38   \n",
       "39       40              58             60               57             55   \n",
       "40       41              95             93               98             98   \n",
       "41       42              80             82               81             83   \n",
       "42       43              82             79               78             71   \n",
       "43       44              55             63               62             66   \n",
       "44       45              89             85               85             85   \n",
       "45       46              59             60               59             60   \n",
       "46       47              87             89               89             91   \n",
       "47       48              34             33               36             38   \n",
       "48       49              70             68               59             69   \n",
       "49       50              27             32               40             25   \n",
       "50       51              78             79               84             76   \n",
       "51       52              44             53               46             43   \n",
       "52       53              76             83               80             84   \n",
       "53       54              52             51               54             45   \n",
       "54       55              77             77               74             72   \n",
       "55       56              99            101               97             95   \n",
       "56       57              45             45               55             54   \n",
       "57       58              55             50               60             58   \n",
       "58       59              97             95               95             94   \n",
       "59       60              91             90               87             90   \n",
       "\n",
       "   overall_cefr  \n",
       "0            A1  \n",
       "1            C1  \n",
       "2            B1  \n",
       "3            B1  \n",
       "4            B2  \n",
       "5            B1  \n",
       "6            A2  \n",
       "7            B2  \n",
       "8            A2  \n",
       "9            B1  \n",
       "10           A2  \n",
       "11           A1  \n",
       "12           A2  \n",
       "13           A2  \n",
       "14           B1  \n",
       "15           A1  \n",
       "16           B1  \n",
       "17           B2  \n",
       "18           B1  \n",
       "19           C1  \n",
       "20           B2  \n",
       "21           C1  \n",
       "22           C1  \n",
       "23           B1  \n",
       "24           A2  \n",
       "25           B1  \n",
       "26           C2  \n",
       "27           C2  \n",
       "28           B1  \n",
       "29           A2  \n",
       "30           B1  \n",
       "31           B1  \n",
       "32           C2  \n",
       "33           A2  \n",
       "34           C1  \n",
       "35           A1  \n",
       "36           B2  \n",
       "37           A2  \n",
       "38           A1  \n",
       "39           B1  \n",
       "40           C2  \n",
       "41           B2  \n",
       "42           B2  \n",
       "43           B1  \n",
       "44           C1  \n",
       "45           B1  \n",
       "46           C1  \n",
       "47           A1  \n",
       "48           B1  \n",
       "49           A1  \n",
       "50           B2  \n",
       "51           A2  \n",
       "52           B2  \n",
       "53           A2  \n",
       "54           B2  \n",
       "55           C2  \n",
       "56           A2  \n",
       "57           B1  \n",
       "58           C2  \n",
       "59           C1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d256c70",
   "metadata": {},
   "source": [
    "## Handling Outliers and Missing Values\n",
    "\n",
    "In this dataset, each test score should be between 0 and 100.\n",
    "However:\n",
    "\n",
    "- Some outliers may exist due to data entry errors (e.g., -5 or 105).\n",
    "\n",
    "As a result we address this issue in 2 steps:\n",
    "\n",
    "- 1: Outlier Detection & Replacement\n",
    "    - Any value < 0 or > 100 is considered invalid.\n",
    "    - Such values are replaced with NaN so they can be treated consistently with other missing values.\n",
    "\n",
    "- 2: Missing Value Imputation by CEFR Group Mean\n",
    "    - Missing values (those just created from outlier replacement) are them imputed with the mean score of the same CEFR group.\n",
    "    - This preserves the relationship between CEFR level and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6a1defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define score columns\n",
    "score_cols = ['speaking_score', 'reading_score', 'listening_score', 'writing_score']\n",
    "\n",
    "# 1. Replace outliers (<0 or >100) with NaN\n",
    "for col in score_cols:\n",
    "    df.loc[(df[col] < 0) | (df[col] > 100), col] = pd.NA\n",
    "\n",
    "# 2. Fill missing values with group mean (based on overall_cefr)\n",
    "for col in score_cols:\n",
    "    df[col] = df.groupby('overall_cefr')[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77b01e",
   "metadata": {},
   "source": [
    "### Verify fix\n",
    "\n",
    "The code below counts outliers per skill column (speaking_score, reading_score, listening_score, writing_score).\n",
    "\n",
    "This helps us:\n",
    "\n",
    "- Confirm whether outliers still exist.\n",
    "- Decide if replacement or imputation is still needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2f820b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers per column:\n",
      "{'speaking_score': np.int64(0), 'reading_score': np.int64(0), 'listening_score': np.int64(0), 'writing_score': np.int64(0)}\n"
     ]
    }
   ],
   "source": [
    "# Define score columns\n",
    "score_cols = ['speaking_score', 'reading_score', 'listening_score', 'writing_score']\n",
    "\n",
    "# Count outliers in each column (values <0 or >100)\n",
    "outliers_count = {}\n",
    "for col in score_cols:\n",
    "    outliers_count[col] = ((df[col] < 0) | (df[col] > 100)).sum()\n",
    "\n",
    "print(\"Number of outliers per column:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c2a2f",
   "metadata": {},
   "source": [
    "## Dropping Unnecessary Columns\n",
    "\n",
    "In some cases, certain columns in the dataset may not be relevant for analysis or modeling.  \n",
    "We can remove such columns to simplify the dataset and reduce noise.\n",
    "\n",
    "**Example:**  \n",
    "The `user_id` column is an identifier and does not contribute to predictive modeling, so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b42785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'user_id' column\n",
    "df.drop('user_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d2a7b",
   "metadata": {},
   "source": [
    "## Removing Duplicate Rows\n",
    "\n",
    "Duplicate rows can occur due to data entry errors or merging issues.\n",
    "If left unhandled, they can bias analysis (e.g., counting a learner’s scores twice).\n",
    "\n",
    "Approach:\n",
    "\n",
    "- Identify duplicate rows using df.duplicated().\n",
    "- For each duplicate row, add a small random adjustment (e.g., ±1 to ±3) to numeric scores (speaking_score, reading_score, listening_score, writing_score).\n",
    "- Ensure the adjusted scores still stay within the valid range 0–100.\n",
    "- Keep the CEFR level the same (since tiny score changes wouldn’t realistically change overall level).\n",
    "- Remove them with drop_duplicates().\n",
    "- Verify that no duplicates remain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c91518e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(292)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Check number of duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "df.duplicated().sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f55cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates_mask = df.duplicated(keep=False)\n",
    "duplicates = df[duplicates_mask]\n",
    "\n",
    "# Apply small random adjustments to duplicates\n",
    "for col in ['speaking_score', 'reading_score', 'listening_score', 'writing_score']:\n",
    "    df.loc[duplicates.index, col] = (\n",
    "        df.loc[duplicates.index, col] + np.random.choice([-2, -1, 1, 2], size=len(duplicates))\n",
    "    ).clip(0, 100)  # keep scores within 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5046eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 4\n"
     ]
    }
   ],
   "source": [
    "# 1. Check number of duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "df.duplicated().sum()\n",
    "\n",
    "# 2. Remove remaining duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0f246",
   "metadata": {},
   "source": [
    "## Recalculate CEFR Levels\n",
    "\n",
    "After addressing missing values, outliers, and duplicates, we recalculate the overall CEFR levels to ensure they align with the updated skill scores.\n",
    "\n",
    "- We calculate each user’s average score across speaking, reading, listening, and writing.\n",
    "- We then assign a CEFR level using the following scale:\n",
    "\n",
    "\n",
    "| Average Score | CEFR |\n",
    "| ------------- | ---- |\n",
    "| 20–40         | A1   |\n",
    "| 41–55         | A2   |\n",
    "| 56–70         | B1   |\n",
    "| 71–85         | B2   |\n",
    "| 86–92         | C1   |\n",
    "| 93+           | C2   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4dc910ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Recalculate CEFR based on average scores\n",
    "\n",
    "def assign_cefr(avg):\n",
    "    if 20 <= avg <= 40:\n",
    "        return \"A1\"\n",
    "    elif 40 < avg <= 55:   # continuous, no gap\n",
    "        return \"A2\"\n",
    "    elif 55 < avg <= 70:\n",
    "        return \"B1\"\n",
    "    elif 70 < avg <= 85:\n",
    "        return \"B2\"\n",
    "    elif 85 < avg <= 92:\n",
    "        return \"C1\"\n",
    "    elif avg > 92:\n",
    "        return \"C2\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Compute average score\n",
    "df[\"average_score\"] = df[[\"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\"]].mean(axis=1)\n",
    "\n",
    "# Assign new CEFR based on average score\n",
    "df[\"overall_cefr\"] = df[\"average_score\"].apply(assign_cefr)\n",
    "\n",
    "# Drop the helper column\n",
    "df.drop(columns=[\"average_score\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55719d",
   "metadata": {},
   "source": [
    "## Round Scores to Integers\n",
    "- Since all scores are percentages, they should be stored as whole numbers.\n",
    "- We round any decimal values to the nearest integer and cast the columns to integer type.\n",
    "- This maintains consistency in the dataset and ensures that all scores are expressed as whole percentage values between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec019518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['speaking_score', 'reading_score', 'listening_score', 'writing_score']] = \\\n",
    "df[['speaking_score', 'reading_score', 'listening_score', 'writing_score']].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc83e71",
   "metadata": {},
   "source": [
    "## Summary Statistics Check\n",
    "\n",
    "Let's take a look at the summary statistics for each score column in our cleaned dataset. This helps us understand the distribution, identify any remaining anomalies, and get a sense of the central tendency and spread of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ce322cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.152087</td>\n",
       "      <td>61.156064</td>\n",
       "      <td>61.203777</td>\n",
       "      <td>60.982107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.256026</td>\n",
       "      <td>21.456621</td>\n",
       "      <td>21.425777</td>\n",
       "      <td>21.227966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.500000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       speaking_score  reading_score  listening_score  writing_score\n",
       "count     1006.000000    1006.000000      1006.000000    1006.000000\n",
       "mean        61.152087      61.156064        61.203777      60.982107\n",
       "std         21.256026      21.456621        21.425777      21.227966\n",
       "min         23.000000      23.000000        23.000000      23.000000\n",
       "25%         43.000000      43.000000        42.000000      43.000000\n",
       "50%         60.500000      61.000000        60.000000      60.000000\n",
       "75%         78.000000      79.000000        80.000000      79.750000\n",
       "max        100.000000     100.000000       100.000000     100.000000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65464e9",
   "metadata": {},
   "source": [
    "### Correct data type check\n",
    "\n",
    "The code below displays info about the dataset, specifically checking the data types of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "886e7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1004 entries, 0 to 1009\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   speaking_score   1004 non-null   int64 \n",
      " 1   reading_score    1004 non-null   int64 \n",
      " 2   listening_score  1004 non-null   int64 \n",
      " 3   writing_score    1004 non-null   int64 \n",
      " 4   overall_cefr     1004 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 47.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72517e1b",
   "metadata": {},
   "source": [
    "## Saving the Cleaned Dataset\n",
    "\n",
    "After completing the data cleaning process, it's good practice to save the cleaned dataset for future use. This ensures that we don't have to repeat the cleaning steps and keeps our project organized.\n",
    "\n",
    "We can save the dataset to a specific folder, for example `data/clean/`, or simply in the current working directory. Using a folder structure helps separate raw and cleaned data, making the workflow more reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86080ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"data/clean/cleaned_lang_proficiency_results.csv\")\n",
    "file_path.parent.mkdir(parents=True, exist_ok=True)  # Creates folder if it doesn't exist\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818528",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we performed a thorough cleaning of our dataset. Key steps included:\n",
    "\n",
    "- Handling missing values by either filling or correcting them.\n",
    "- Fixing outliers and erroneous values in the numeric score columns.\n",
    "- Ensuring consistency across all columns, particularly the `overall_cefr` levels.\n",
    "- Dropping unnecessary or redundant columns.\n",
    "- Adjusting duplicate values appropriately.\n",
    "- Verifying that all data types were appropriate for analysis.\n",
    "\n",
    "After cleaning, the dataset is now consistent, complete, and ready for further analysis or modeling. Summary statistics confirm that all scores are within reasonable ranges, and categorical labels accurately reflect the underlying numeric data. These final checks give us confidence in the integrity of the dataset moving forward.\n",
    "\n",
    "### Next steps\n",
    "- 03_eda.ipynb: This notebook will focus on exploring the cleaned dataset. We will generate visualizations, examine distributions, check correlations, and identify patterns or trends in the data to inform future modeling decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
