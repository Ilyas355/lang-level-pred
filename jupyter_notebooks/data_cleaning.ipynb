{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2d5caa",
   "metadata": {},
   "source": [
    "# 02. Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2484af",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Remove duplicate entries from the dataset to ensure data quality\n",
    "- Handle missing values using appropriate strategies\n",
    "- Standardize data formats and fix inconsistent data types\n",
    "\n",
    "## Inputs\n",
    "- A cleaned version of the raw dataset file from data collection phase (i.e lang_proficiency_results)\n",
    "\n",
    "## Outputs\n",
    "- Cleaned dataset with consistent formatting and data types\n",
    "- Documentation of data cleaning decisions and transformations applied\n",
    "- Summary statistics of data quality improvements\n",
    "\n",
    "## Additional information\n",
    "- All cleaning operations are documented with clear rationale for reproducibility\n",
    "- Any data removed or significantly modified is logged for transparency\n",
    "- Raw data backups are preserved and data quality metrics tracked throughout the process\n",
    "- Missing values and outliers are handled using domain-appropriate strategies with clear documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf875c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f144df6",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262d735",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6647d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd36c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a5bfd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c06e13",
   "metadata": {},
   "source": [
    "# Data loading and basic exploration\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f40cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.1\n",
      "NumPy version: 2.3.1\n",
      "matplotlib version: 3.10.5\n"
     ]
    }
   ],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd1233",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data folder and what folder we are currently in. \n",
    "- Subsequently we aren't in the right folder so the current path is set to the parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a71e9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\raw:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lang_proficiency_results_raw.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/raw\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a5f3d",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This code loads the dataset that is then displayed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db14c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = Path(\"data/raw/lang_proficiency_results_raw.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a875771",
   "metadata": {},
   "source": [
    "## Identifying problems in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d75326",
   "metadata": {},
   "source": [
    "### Check Missing Values in Dataset\n",
    "This code analyzes and displays missing values in our bulldozer dataset:\n",
    "- Uses pandas' isna() function to identify missing values\n",
    "- Counts total missing values per column using sum()\n",
    "- Sorts results in descending order to highlight columns with most missing data\n",
    "\n",
    "Previously this showed multiple missing values in some of the columns but i mistakenly ran it again after fixing the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8735828e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_cefr       16\n",
       "listening_score    16\n",
       "speaking_score     14\n",
       "reading_score       9\n",
       "writing_score       8\n",
       "user_id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130a938",
   "metadata": {},
   "source": [
    "### Check for Duplicates\n",
    "This code checks if any duplicates exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6885bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>overall_cefr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>508</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>819</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>453</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>369</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>243</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>930</td>\n",
       "      <td>82.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>263</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>811</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>319</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>50</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  speaking_score  reading_score  listening_score  writing_score  \\\n",
       "1000      508            32.0           31.0             35.0           39.0   \n",
       "1001      819            57.0           55.0             58.0           56.0   \n",
       "1002      453            61.0           59.0             57.0           70.0   \n",
       "1003      369            53.0           55.0             47.0           53.0   \n",
       "1004      243            51.0           47.0             41.0           48.0   \n",
       "1005      930            82.0           72.0             71.0           74.0   \n",
       "1006      263            89.0           91.0             90.0           88.0   \n",
       "1007      811            29.0           40.0             27.0           31.0   \n",
       "1008      319            52.0           50.0             50.0           47.0   \n",
       "1009       50            27.0           32.0             40.0           25.0   \n",
       "\n",
       "     overall_cefr  \n",
       "1000           A1  \n",
       "1001           B1  \n",
       "1002           B1  \n",
       "1003           A2  \n",
       "1004           A2  \n",
       "1005           B2  \n",
       "1006           C1  \n",
       "1007           A1  \n",
       "1008           A2  \n",
       "1009           A1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Count total duplicates\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# View the duplicate rows (if any)\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a6afa",
   "metadata": {},
   "source": [
    "## Check for outliers\n",
    "This code checks the dataset to see if any scores exist outide of the range 100 < x < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389ced1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaking_score: 0 outliers\n",
      "listening_score: 0 outliers\n",
      "reading_score: 7 outliers\n",
      "writing_score: 0 outliers\n"
     ]
    }
   ],
   "source": [
    "# Check outliers for all score columns\n",
    "score_columns = ['speaking_score', 'listening_score', 'reading_score', 'writing_score']\n",
    "\n",
    "for col in score_columns:\n",
    "   outliers = ((df[col] < 1) | (df[col] > 100)).sum()\n",
    "   print(f\"{col}: {outliers} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f02de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              int64\n",
       "speaking_score     float64\n",
       "reading_score      float64\n",
       "listening_score    float64\n",
       "writing_score      float64\n",
       "overall_cefr        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286607d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1010 entries, 0 to 1009\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   user_id          1010 non-null   int64  \n",
      " 1   speaking_score   996 non-null    float64\n",
      " 2   reading_score    1001 non-null   float64\n",
      " 3   listening_score  994 non-null    float64\n",
      " 4   writing_score    1002 non-null   float64\n",
      " 5   overall_cefr     994 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 47.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaadbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['listening_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02e086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['speaking_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['writing_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f9cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-numeric values exist\n",
    "df['reading_score'].dtype == 'object'  # True if column contains strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7404e34",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c378fc0",
   "metadata": {},
   "source": [
    "### Handling Missing Values by Group Mean Imputation\n",
    "\n",
    "In this dataset, each user's skill scores (e.g., Speaking, Listening, Reading, Writing) directly contribute to their **overall CEFR level**.  \n",
    "When a score is missing, replacing it with a general mean across all CEFR levels could distort the relationship between skills and the overall level.\n",
    "\n",
    "We replace missing values in each skill **with the mean score for that skill within the same overall CEFR group**.  \n",
    "This ensures that imputed values are consistent with the performance range typical of that CEFR level.\n",
    "\n",
    "**Example:**  \n",
    "If a `speaking_score` is missing for a B2-level user, we:\n",
    "1. Look at all B2 users’ speaking scores.\n",
    "2. Calculate the mean speaking score for the B2 group.\n",
    "3. Fill the missing value with this mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
