{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40204ac0",
   "metadata": {},
   "source": [
    "# 04. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36598c38",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The goal of this notebook is to prepare the dataset for machine learning by creating, transforming, and encoding features that improve the model’s ability to predict CEFR levels. Specifically, we aim to:\n",
    "\n",
    "- Encode the categorical target variable (CEFR levels) into numerical labels suitable for classification.  \n",
    "- Ensure feature scaling/normalization so that all skill scores contribute fairly to the model.  \n",
    "- Explore potential derived features (e.g., average score, skill differences) that may enhance predictive performance.  \n",
    "- Split the dataset into training and test sets with stratification to preserve class distribution.  \n",
    "- Generate a final feature matrix (`X`) and target vector (`y`) ready for model training.  \n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Cleaned dataset: `data/clean/cleaned_lang_proficiency_results.csv`  \n",
    "- Columns: `speaking_score`, `reading_score`, `listening_score`, `writing_score`, `overall_cefr`  \n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Encoded target labels for CEFR levels  \n",
    "- Scaled/normalized feature set  \n",
    "- Optional engineered features (e.g., mean score, modality balance)  \n",
    "- Train/test splits saved for modeling  \n",
    "- Final processed dataset in a format ready for the ML notebook  \n",
    "\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "Feature engineering bridges the gap between raw data and machine learning readiness. Since the business requirement is **automatic learner placement and personalized recommendations**, ensuring that CEFR levels can be predicted accurately depends on well-prepared features. In this step, we transform the raw language skill scores into an optimized input space for classification models, laying the foundation for robust and interpretable predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43581c5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b591f7",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2af5b7",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea55cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304e7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fe9ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c08e6d",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ed86",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data/clean folder and what folder we are currently in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418fe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\clean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cleaned_lang_proficiency_results.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/clean\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cb192",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This code loads the dataset from the data/clean folder that is then displayed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255ae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = Path(\"data/clean/cleaned_lang_proficiency_results.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c14f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f7b2a",
   "metadata": {},
   "source": [
    "## 1. Target Variable Encoding\n",
    "\n",
    "The target variable `overall_cefr` is categorical (A1–C2).  \n",
    "To use it in machine learning classification models, we need to encode it into numeric labels.  \n",
    "\n",
    "We will apply the following mapping:\n",
    "\n",
    "- A1 → 0  \n",
    "- A2 → 1  \n",
    "- B1 → 2  \n",
    "- B2 → 3  \n",
    "- C1 → 4  \n",
    "- C2 → 5  \n",
    "\n",
    "This preserves the natural order of proficiency levels while making the target compatible with scikit-learn classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5beb120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Target variable encoded successfully!\n",
      "  overall_cefr  cefr_encoded\n",
      "0           A1             0\n",
      "1           C1             4\n",
      "2           B1             2\n",
      "3           B1             2\n",
      "4           B2             3\n",
      "5           B1             2\n",
      "6           A2             1\n",
      "7           B2             3\n",
      "8           A2             1\n",
      "9           B1             2\n",
      "\n",
      "Encoded CEFR distribution:\n",
      "cefr_encoded\n",
      "0    208\n",
      "1    219\n",
      "2    208\n",
      "3    192\n",
      "4     94\n",
      "5     83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define mapping for CEFR levels\n",
    "cefr_mapping = {\"A1\": 0, \"A2\": 1, \"B1\": 2, \"B2\": 3, \"C1\": 4, \"C2\": 5}\n",
    "\n",
    "# Apply mapping to target column\n",
    "df[\"cefr_encoded\"] = df[\"overall_cefr\"].map(cefr_mapping)\n",
    "\n",
    "# Verify encoding\n",
    "print(\"✅ Target variable encoded successfully!\")\n",
    "print(df[[\"overall_cefr\", \"cefr_encoded\"]].head(10))\n",
    "\n",
    "# Check value counts to confirm distribution\n",
    "print(\"\\nEncoded CEFR distribution:\")\n",
    "print(df[\"cefr_encoded\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3a180",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "In this step, we create additional features from the four base skill scores (*speaking, reading, listening, writing*).  \n",
    "These engineered features provide richer insights into learner profiles and enhance the model’s ability to predict CEFR levels.  \n",
    "\n",
    "The following **8 engineered features** are created:\n",
    "\n",
    "1. **strongest_skill** → identifies the learner’s best-performing skill.  \n",
    "2. **weakest_skill** → identifies the learner’s lowest-performing skill (main bottleneck).  \n",
    "3. **second_weakest_skill** → captures the learner’s secondary weakness for targeted recommendations.  \n",
    "4. **skill_std** → standard deviation across the four skills, measuring balance vs imbalance.  \n",
    "5. **strength_weakness_gap** → difference between strongest and weakest skill scores.  \n",
    "6. **productive_receptive_ratio** → ratio of productive (speaking + writing) to receptive (reading + listening) skills.  \n",
    "7. **avg_score** → mean score across all four skills, proxy for overall proficiency.  \n",
    "8. **learning_profile** → categorical label:  \n",
    "   - *Balanced* → skills are evenly developed (low variance).  \n",
    "   - *Uneven Development* → large discrepancies between strengths and weaknesses.  \n",
    "\n",
    "These features not only improve predictive modeling but also support the business requirement of **automatic learner placement with personalized recommendations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f1a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap threshold for Uneven Development: 11.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>overall_cefr</th>\n",
       "      <th>cefr_encoded</th>\n",
       "      <th>strongest_skill</th>\n",
       "      <th>weakest_skill</th>\n",
       "      <th>second_weakest_skill</th>\n",
       "      <th>skill_std</th>\n",
       "      <th>strength_weakness_gap</th>\n",
       "      <th>productive_receptive_ratio</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>learning_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>reading</td>\n",
       "      <td>speaking</td>\n",
       "      <td>listening</td>\n",
       "      <td>5.972158</td>\n",
       "      <td>14</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>31.50</td>\n",
       "      <td>Uneven Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>C1</td>\n",
       "      <td>4</td>\n",
       "      <td>speaking</td>\n",
       "      <td>writing</td>\n",
       "      <td>listening</td>\n",
       "      <td>1.707825</td>\n",
       "      <td>4</td>\n",
       "      <td>1.005525</td>\n",
       "      <td>90.75</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>reading</td>\n",
       "      <td>writing</td>\n",
       "      <td>speaking</td>\n",
       "      <td>4.272002</td>\n",
       "      <td>9</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>61.25</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>speaking</td>\n",
       "      <td>listening</td>\n",
       "      <td>listening</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>9</td>\n",
       "      <td>1.035398</td>\n",
       "      <td>57.50</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>B2</td>\n",
       "      <td>3</td>\n",
       "      <td>listening</td>\n",
       "      <td>reading</td>\n",
       "      <td>speaking</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>79.25</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaking_score  reading_score  listening_score  writing_score overall_cefr  \\\n",
       "0              24             38               30             34           A1   \n",
       "1              93             91               90             89           C1   \n",
       "2              62             64               64             55           B1   \n",
       "3              63             59               54             54           B1   \n",
       "4              79             74               85             79           B2   \n",
       "\n",
       "   cefr_encoded strongest_skill weakest_skill second_weakest_skill  skill_std  \\\n",
       "0             0         reading      speaking            listening   5.972158   \n",
       "1             4        speaking       writing            listening   1.707825   \n",
       "2             2         reading       writing             speaking   4.272002   \n",
       "3             2        speaking     listening            listening   4.358899   \n",
       "4             3       listening       reading             speaking   4.500000   \n",
       "\n",
       "   strength_weakness_gap  productive_receptive_ratio  avg_score  \\\n",
       "0                     14                    0.852941      31.50   \n",
       "1                      4                    1.005525      90.75   \n",
       "2                      9                    0.914062      61.25   \n",
       "3                      9                    1.035398      57.50   \n",
       "4                     11                    0.993711      79.25   \n",
       "\n",
       "     learning_profile  \n",
       "0  Uneven Development  \n",
       "1            Balanced  \n",
       "2            Balanced  \n",
       "3            Balanced  \n",
       "4            Balanced  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of core skill columns\n",
    "skill_cols = [\"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\"]\n",
    "\n",
    "# Strongest and weakest skills\n",
    "df[\"strongest_skill\"] = df[skill_cols].idxmax(axis=1).str.replace(\"_score\", \"\")\n",
    "df[\"weakest_skill\"] = df[skill_cols].idxmin(axis=1).str.replace(\"_score\", \"\")\n",
    "\n",
    "# Second weakest skill\n",
    "df[\"second_weakest_skill\"] = df[skill_cols].apply(\n",
    "    lambda row: row.sort_values().index[1].replace(\"_score\", \"\"), axis=1\n",
    ")\n",
    "\n",
    "# Skill standard deviation (imbalance indicator)\n",
    "df[\"skill_std\"] = df[skill_cols].std(axis=1)\n",
    "\n",
    "# Gap between strongest and weakest\n",
    "df[\"strength_weakness_gap\"] = df[skill_cols].max(axis=1) - df[skill_cols].min(axis=1)\n",
    "\n",
    "# Productive (speaking+writing) vs receptive (reading+listening) ratio\n",
    "df[\"productive_receptive_ratio\"] = (\n",
    "    (df[\"speaking_score\"] + df[\"writing_score\"]) /\n",
    "    (df[\"reading_score\"] + df[\"listening_score\"] + 1e-6)  # avoid division by zero\n",
    ")\n",
    "\n",
    "# Average score\n",
    "df[\"avg_score\"] = df[skill_cols].mean(axis=1)\n",
    "\n",
    "# Learning profile classification\n",
    "\n",
    "# Determine threshold (75th percentile of gaps)\n",
    "gap_threshold = df[\"strength_weakness_gap\"].quantile(0.75)\n",
    "print(f\"Gap threshold for Uneven Development: {gap_threshold:.2f}\")\n",
    "\n",
    "# Create learning profile classification\n",
    "df[\"learning_profile\"] = np.where(\n",
    "    df[\"strength_weakness_gap\"] > gap_threshold,\n",
    "    \"Uneven Development\",\n",
    "    \"Balanced\"\n",
    ")\n",
    "\n",
    "# Preview engineered features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8665c",
   "metadata": {},
   "source": [
    "## 6. Scaling / Normalization\n",
    "\n",
    "Machine learning models are sensitive to the scale of input features, especially distance-based methods (e.g., KNN, SVM) and gradient-based optimizers (e.g., Logistic Regression, Neural Networks).  \n",
    "Since the skill scores (0–100) and engineered features (e.g., ratios, gaps) exist on different scales, we standardize all numeric features to have:\n",
    "\n",
    "- Mean = 0  \n",
    "- Standard Deviation = 1  \n",
    "\n",
    "This ensures that each feature contributes fairly to the model and avoids bias toward high-magnitude features.  \n",
    "We use **StandardScaler** from scikit-learn for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e448d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>strength_weakness_gap</th>\n",
       "      <th>skill_std</th>\n",
       "      <th>productive_receptive_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.748439</td>\n",
       "      <td>-1.078990</td>\n",
       "      <td>-1.456782</td>\n",
       "      <td>-1.270976</td>\n",
       "      <td>-1.409432</td>\n",
       "      <td>1.427690</td>\n",
       "      <td>1.209576</td>\n",
       "      <td>-1.584816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500880</td>\n",
       "      <td>1.393353</td>\n",
       "      <td>1.346852</td>\n",
       "      <td>1.322354</td>\n",
       "      <td>1.412041</td>\n",
       "      <td>-1.225282</td>\n",
       "      <td>-1.273163</td>\n",
       "      <td>0.016070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.133857</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>-0.280795</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>0.219728</td>\n",
       "      <td>-0.943540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088133</td>\n",
       "      <td>-0.099382</td>\n",
       "      <td>-0.335328</td>\n",
       "      <td>-0.327947</td>\n",
       "      <td>-0.171317</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>0.270320</td>\n",
       "      <td>0.329497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.600337</td>\n",
       "      <td>1.113216</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.864413</td>\n",
       "      <td>0.631798</td>\n",
       "      <td>0.352470</td>\n",
       "      <td>-0.107883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaking_score  reading_score  listening_score  writing_score  avg_score  \\\n",
       "0       -1.748439      -1.078990        -1.456782      -1.270976  -1.409432   \n",
       "1        1.500880       1.393353         1.346852       1.322354   1.412041   \n",
       "2        0.041041       0.133857         0.131944      -0.280795   0.007257   \n",
       "3        0.088133      -0.099382        -0.335328      -0.327947  -0.171317   \n",
       "4        0.841598       0.600337         1.113216       0.850840   0.864413   \n",
       "\n",
       "   strength_weakness_gap  skill_std  productive_receptive_ratio  \n",
       "0               1.427690   1.209576                   -1.584816  \n",
       "1              -1.225282  -1.273163                    0.016070  \n",
       "2               0.101204   0.219728                   -0.943540  \n",
       "3               0.101204   0.270320                    0.329497  \n",
       "4               0.631798   0.352470                   -0.107883  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 6: Scaling / Normalization ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select feature columns (exclude target)\n",
    "feature_cols = [\n",
    "    \"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\",\n",
    "    \"avg_score\", \"strength_weakness_gap\", \"skill_std\",\n",
    "    \"productive_receptive_ratio\"\n",
    "]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "X_scaled = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "\n",
    "# Preview scaled features\n",
    "X_scaled_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
