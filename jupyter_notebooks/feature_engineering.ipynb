{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40204ac0",
   "metadata": {},
   "source": [
    "# 04. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36598c38",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The goal of this notebook is to prepare the dataset for machine learning by creating, transforming, and encoding features that improve the model’s ability to predict CEFR levels. Specifically, we aim to:\n",
    "\n",
    "- Encode the categorical target variable (CEFR levels) into numerical labels suitable for classification.  \n",
    "- Ensure feature scaling/normalization so that all skill scores contribute fairly to the model.  \n",
    "- Explore potential derived features (e.g., average score, skill differences) that may enhance predictive performance.  \n",
    "- Split the dataset into training and test sets with stratification to preserve class distribution.  \n",
    "- Generate a final feature matrix (`X`) and target vector (`y`) ready for model training.  \n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Cleaned dataset: `data/clean/cleaned_lang_proficiency_results.csv`  \n",
    "- Columns: `speaking_score`, `reading_score`, `listening_score`, `writing_score`, `overall_cefr`  \n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Encoded target labels for CEFR levels  \n",
    "- Scaled/normalized feature set  \n",
    "- Optional engineered features (e.g., mean score, modality balance)  \n",
    "- Train/test splits saved for modeling  \n",
    "- Final processed dataset in a format ready for the ML notebook  \n",
    "\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "Feature engineering bridges the gap between raw data and machine learning readiness. Since the business requirement is **automatic learner placement and personalized recommendations**, ensuring that CEFR levels can be predicted accurately depends on well-prepared features. In this step, we transform the raw language skill scores into an optimized input space for classification models, laying the foundation for robust and interpretable predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43581c5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b591f7",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2af5b7",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea55cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304e7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fe9ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c08e6d",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ed86",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data/clean folder and what folder we are currently in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418fe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\clean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cleaned_lang_proficiency_results.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/clean\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cb192",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This code loads the dataset from the data/clean folder that is then displayed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255ae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = Path(\"data/clean/cleaned_lang_proficiency_results.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c14f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f7b2a",
   "metadata": {},
   "source": [
    "## 1. Target Variable Encoding\n",
    "\n",
    "The target variable `overall_cefr` is categorical (A1–C2).  \n",
    "To use it in machine learning classification models, we need to encode it into numeric labels.  \n",
    "\n",
    "We will apply the following mapping:\n",
    "\n",
    "- A1 → 0  \n",
    "- A2 → 1  \n",
    "- B1 → 2  \n",
    "- B2 → 3  \n",
    "- C1 → 4  \n",
    "- C2 → 5  \n",
    "\n",
    "This preserves the natural order of proficiency levels while making the target compatible with scikit-learn classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5beb120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Target variable encoded successfully!\n",
      "  overall_cefr  cefr_encoded\n",
      "0           A1             0\n",
      "1           C1             4\n",
      "2           B1             2\n",
      "3           B1             2\n",
      "4           B2             3\n",
      "5           B1             2\n",
      "6           A2             1\n",
      "7           B2             3\n",
      "8           A2             1\n",
      "9           B1             2\n",
      "\n",
      "Encoded CEFR distribution:\n",
      "cefr_encoded\n",
      "0    208\n",
      "1    219\n",
      "2    208\n",
      "3    192\n",
      "4     94\n",
      "5     83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define mapping for CEFR levels\n",
    "cefr_mapping = {\"A1\": 0, \"A2\": 1, \"B1\": 2, \"B2\": 3, \"C1\": 4, \"C2\": 5}\n",
    "\n",
    "# Apply mapping to target column\n",
    "df[\"cefr_encoded\"] = df[\"overall_cefr\"].map(cefr_mapping)\n",
    "\n",
    "# Verify encoding\n",
    "print(\"✅ Target variable encoded successfully!\")\n",
    "print(df[[\"overall_cefr\", \"cefr_encoded\"]].head(10))\n",
    "\n",
    "# Check value counts to confirm distribution\n",
    "print(\"\\nEncoded CEFR distribution:\")\n",
    "print(df[\"cefr_encoded\"].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
