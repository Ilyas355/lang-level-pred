{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40204ac0",
   "metadata": {},
   "source": [
    "# 04. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36598c38",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The goal of this notebook is to prepare the dataset for machine learning by creating, transforming, and encoding features that improve the model’s ability to predict CEFR levels. Specifically, we aim to:\n",
    "\n",
    "- Encode the categorical target variable (CEFR levels) into numerical labels suitable for classification.  \n",
    "- Ensure feature scaling/normalization so that all skill scores contribute fairly to the model.  \n",
    "- Explore potential derived features (e.g., average score, skill differences) that may enhance predictive performance.  \n",
    "- Split the dataset into training and test sets with stratification to preserve class distribution.  \n",
    "- Generate a final feature matrix (`X`) and target vector (`y`) ready for model training.  \n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Cleaned dataset: `data/clean/cleaned_lang_proficiency_results.csv`  \n",
    "- Columns: `speaking_score`, `reading_score`, `listening_score`, `writing_score`, `overall_cefr`  \n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Encoded target labels for CEFR levels  \n",
    "- Scaled/normalized feature set  \n",
    "- Optional engineered features (e.g., mean score, modality balance)  \n",
    "- Train/test splits saved for modeling  \n",
    "- Final processed dataset in a format ready for the ML notebook  \n",
    "\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "Feature engineering bridges the gap between raw data and machine learning readiness. Since the business requirement is **automatic learner placement and personalized recommendations**, ensuring that CEFR levels can be predicted accurately depends on well-prepared features. In this step, we transform the raw language skill scores into an optimized input space for classification models, laying the foundation for robust and interpretable predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43581c5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b591f7",
   "metadata": {},
   "source": [
    "# Project Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2af5b7",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to the folder the code of this project is currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea55cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\husse\\\\OneDrive\\\\Projects\\\\lang-level-pred\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304e7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\husse\\OneDrive\\Projects\\lang-level-pred\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# swtich to project root directory\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fe9ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c08e6d",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "This code block imports fundamental Python libraries for data analysis and visualization and checks their versions\n",
    "\n",
    "- pandas: For data manipulation and analysis\n",
    "- numpy: For numerical computations\n",
    "- matplotlib: For creating visualizations and plots\n",
    "\n",
    "The version checks help ensure:\n",
    "- Code compatibility across different environments\n",
    "- Reproducibility of analysis\n",
    "- Easy debugging of version-specific issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ed86",
   "metadata": {},
   "source": [
    "### List Files and Folders\n",
    "- This code shows what files and folders are in our data/clean folder and what folder we are currently in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418fe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files/folders available in data\\clean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cleaned_lang_proficiency_results.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"data/clean\")\n",
    "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cb192",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This code loads the dataset from the data/clean folder that is then displayed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255ae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = Path(\"data/clean/cleaned_lang_proficiency_results.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c14f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f7b2a",
   "metadata": {},
   "source": [
    "## 1. Target Variable Encoding\n",
    "\n",
    "The target variable `overall_cefr` is categorical (A1–C2).  \n",
    "To use it in machine learning classification models, we need to encode it into numeric labels.  \n",
    "\n",
    "We will apply the following mapping:\n",
    "\n",
    "- A1 → 0  \n",
    "- A2 → 1  \n",
    "- B1 → 2  \n",
    "- B2 → 3  \n",
    "- C1 → 4  \n",
    "- C2 → 5  \n",
    "\n",
    "This preserves the natural order of proficiency levels while making the target compatible with scikit-learn classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5beb120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Target variable encoded successfully!\n",
      "  overall_cefr  cefr_encoded\n",
      "0           A1             0\n",
      "1           C1             4\n",
      "2           B1             2\n",
      "3           B1             2\n",
      "4           B2             3\n",
      "5           B1             2\n",
      "6           A2             1\n",
      "7           B2             3\n",
      "8           A2             1\n",
      "9           B1             2\n",
      "\n",
      "Encoded CEFR distribution:\n",
      "cefr_encoded\n",
      "0    208\n",
      "1    219\n",
      "2    208\n",
      "3    192\n",
      "4     94\n",
      "5     83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define mapping for CEFR levels\n",
    "cefr_mapping = {\"A1\": 0, \"A2\": 1, \"B1\": 2, \"B2\": 3, \"C1\": 4, \"C2\": 5}\n",
    "\n",
    "# Apply mapping to target column\n",
    "df[\"cefr_encoded\"] = df[\"overall_cefr\"].map(cefr_mapping)\n",
    "\n",
    "# Verify encoding\n",
    "print(\"✅ Target variable encoded successfully!\")\n",
    "print(df[[\"overall_cefr\", \"cefr_encoded\"]].head(10))\n",
    "\n",
    "# Check value counts to confirm distribution\n",
    "print(\"\\nEncoded CEFR distribution:\")\n",
    "print(df[\"cefr_encoded\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3a180",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "In this step, we create additional features from the four base skill scores (*speaking, reading, listening, writing*).  \n",
    "These engineered features provide richer insights into learner profiles and enhance the model’s ability to predict CEFR levels.  \n",
    "\n",
    "The following **8 engineered features** are created:\n",
    "\n",
    "1. **strongest_skill** → identifies the learner’s best-performing skill.  \n",
    "2. **weakest_skill** → identifies the learner’s lowest-performing skill (main bottleneck).  \n",
    "3. **second_weakest_skill** → captures the learner’s secondary weakness for targeted recommendations.  \n",
    "4. **skill_std** → standard deviation across the four skills, measuring balance vs imbalance.  \n",
    "5. **strength_weakness_gap** → difference between strongest and weakest skill scores.  \n",
    "6. **productive_receptive_ratio** → ratio of productive (speaking + writing) to receptive (reading + listening) skills.  \n",
    "7. **avg_score** → mean score across all four skills, proxy for overall proficiency.  \n",
    "8. **learning_profile** → categorical label:  \n",
    "   - *Balanced* → skills are evenly developed (low variance).  \n",
    "   - *Uneven Development* → large discrepancies between strengths and weaknesses.  \n",
    "\n",
    "These features not only improve predictive modeling but also support the business requirement of **automatic learner placement with personalized recommendations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f1a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap threshold for Uneven Development: 11.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>overall_cefr</th>\n",
       "      <th>cefr_encoded</th>\n",
       "      <th>strongest_skill</th>\n",
       "      <th>weakest_skill</th>\n",
       "      <th>second_weakest_skill</th>\n",
       "      <th>skill_std</th>\n",
       "      <th>strength_weakness_gap</th>\n",
       "      <th>productive_receptive_ratio</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>learning_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>reading</td>\n",
       "      <td>speaking</td>\n",
       "      <td>listening</td>\n",
       "      <td>5.972158</td>\n",
       "      <td>14</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>31.50</td>\n",
       "      <td>Uneven Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>C1</td>\n",
       "      <td>4</td>\n",
       "      <td>speaking</td>\n",
       "      <td>writing</td>\n",
       "      <td>listening</td>\n",
       "      <td>1.707825</td>\n",
       "      <td>4</td>\n",
       "      <td>1.005525</td>\n",
       "      <td>90.75</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>reading</td>\n",
       "      <td>writing</td>\n",
       "      <td>speaking</td>\n",
       "      <td>4.272002</td>\n",
       "      <td>9</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>61.25</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>speaking</td>\n",
       "      <td>listening</td>\n",
       "      <td>listening</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>9</td>\n",
       "      <td>1.035398</td>\n",
       "      <td>57.50</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>B2</td>\n",
       "      <td>3</td>\n",
       "      <td>listening</td>\n",
       "      <td>reading</td>\n",
       "      <td>speaking</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>79.25</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaking_score  reading_score  listening_score  writing_score overall_cefr  \\\n",
       "0              24             38               30             34           A1   \n",
       "1              93             91               90             89           C1   \n",
       "2              62             64               64             55           B1   \n",
       "3              63             59               54             54           B1   \n",
       "4              79             74               85             79           B2   \n",
       "\n",
       "   cefr_encoded strongest_skill weakest_skill second_weakest_skill  skill_std  \\\n",
       "0             0         reading      speaking            listening   5.972158   \n",
       "1             4        speaking       writing            listening   1.707825   \n",
       "2             2         reading       writing             speaking   4.272002   \n",
       "3             2        speaking     listening            listening   4.358899   \n",
       "4             3       listening       reading             speaking   4.500000   \n",
       "\n",
       "   strength_weakness_gap  productive_receptive_ratio  avg_score  \\\n",
       "0                     14                    0.852941      31.50   \n",
       "1                      4                    1.005525      90.75   \n",
       "2                      9                    0.914062      61.25   \n",
       "3                      9                    1.035398      57.50   \n",
       "4                     11                    0.993711      79.25   \n",
       "\n",
       "     learning_profile  \n",
       "0  Uneven Development  \n",
       "1            Balanced  \n",
       "2            Balanced  \n",
       "3            Balanced  \n",
       "4            Balanced  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of core skill columns\n",
    "skill_cols = [\"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\"]\n",
    "\n",
    "# Strongest and weakest skills\n",
    "df[\"strongest_skill\"] = df[skill_cols].idxmax(axis=1).str.replace(\"_score\", \"\")\n",
    "df[\"weakest_skill\"] = df[skill_cols].idxmin(axis=1).str.replace(\"_score\", \"\")\n",
    "\n",
    "# Second weakest skill\n",
    "df[\"second_weakest_skill\"] = df[skill_cols].apply(\n",
    "    lambda row: row.sort_values().index[1].replace(\"_score\", \"\"), axis=1\n",
    ")\n",
    "\n",
    "# Skill standard deviation (imbalance indicator)\n",
    "df[\"skill_std\"] = df[skill_cols].std(axis=1)\n",
    "\n",
    "# Gap between strongest and weakest\n",
    "df[\"strength_weakness_gap\"] = df[skill_cols].max(axis=1) - df[skill_cols].min(axis=1)\n",
    "\n",
    "# Productive (speaking+writing) vs receptive (reading+listening) ratio\n",
    "df[\"productive_receptive_ratio\"] = (\n",
    "    (df[\"speaking_score\"] + df[\"writing_score\"]) /\n",
    "    (df[\"reading_score\"] + df[\"listening_score\"] + 1e-6)  # avoid division by zero\n",
    ")\n",
    "\n",
    "# Average score\n",
    "df[\"avg_score\"] = df[skill_cols].mean(axis=1)\n",
    "\n",
    "# Learning profile classification\n",
    "\n",
    "# Determine threshold (75th percentile of gaps)\n",
    "gap_threshold = df[\"strength_weakness_gap\"].quantile(0.75)\n",
    "print(f\"Gap threshold for Uneven Development: {gap_threshold:.2f}\")\n",
    "\n",
    "# Create learning profile classification\n",
    "df[\"learning_profile\"] = np.where(\n",
    "    df[\"strength_weakness_gap\"] > gap_threshold,\n",
    "    \"Uneven Development\",\n",
    "    \"Balanced\"\n",
    ")\n",
    "\n",
    "# Preview engineered features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8665c",
   "metadata": {},
   "source": [
    "## 2. Scaling / Normalization\n",
    "\n",
    "Machine learning models are sensitive to the scale of input features, especially distance-based methods (e.g., KNN, SVM) and gradient-based optimizers (e.g., Logistic Regression, Neural Networks).  \n",
    "Since the skill scores (0–100) and engineered features (e.g., ratios, gaps) exist on different scales, we standardize all numeric features to have:\n",
    "\n",
    "- Mean = 0  \n",
    "- Standard Deviation = 1  \n",
    "\n",
    "This ensures that each feature contributes fairly to the model and avoids bias toward high-magnitude features.  \n",
    "We use **StandardScaler** from scikit-learn for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e448d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>strength_weakness_gap</th>\n",
       "      <th>skill_std</th>\n",
       "      <th>productive_receptive_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.748439</td>\n",
       "      <td>-1.078990</td>\n",
       "      <td>-1.456782</td>\n",
       "      <td>-1.270976</td>\n",
       "      <td>-1.409432</td>\n",
       "      <td>1.427690</td>\n",
       "      <td>1.209576</td>\n",
       "      <td>-1.584816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500880</td>\n",
       "      <td>1.393353</td>\n",
       "      <td>1.346852</td>\n",
       "      <td>1.322354</td>\n",
       "      <td>1.412041</td>\n",
       "      <td>-1.225282</td>\n",
       "      <td>-1.273163</td>\n",
       "      <td>0.016070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.133857</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>-0.280795</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>0.219728</td>\n",
       "      <td>-0.943540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088133</td>\n",
       "      <td>-0.099382</td>\n",
       "      <td>-0.335328</td>\n",
       "      <td>-0.327947</td>\n",
       "      <td>-0.171317</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>0.270320</td>\n",
       "      <td>0.329497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.600337</td>\n",
       "      <td>1.113216</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.864413</td>\n",
       "      <td>0.631798</td>\n",
       "      <td>0.352470</td>\n",
       "      <td>-0.107883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaking_score  reading_score  listening_score  writing_score  avg_score  \\\n",
       "0       -1.748439      -1.078990        -1.456782      -1.270976  -1.409432   \n",
       "1        1.500880       1.393353         1.346852       1.322354   1.412041   \n",
       "2        0.041041       0.133857         0.131944      -0.280795   0.007257   \n",
       "3        0.088133      -0.099382        -0.335328      -0.327947  -0.171317   \n",
       "4        0.841598       0.600337         1.113216       0.850840   0.864413   \n",
       "\n",
       "   strength_weakness_gap  skill_std  productive_receptive_ratio  \n",
       "0               1.427690   1.209576                   -1.584816  \n",
       "1              -1.225282  -1.273163                    0.016070  \n",
       "2               0.101204   0.219728                   -0.943540  \n",
       "3               0.101204   0.270320                    0.329497  \n",
       "4               0.631798   0.352470                   -0.107883  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 6: Scaling / Normalization ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select feature columns (exclude target)\n",
    "feature_cols = [\n",
    "    \"speaking_score\", \"reading_score\", \"listening_score\", \"writing_score\",\n",
    "    \"avg_score\", \"strength_weakness_gap\", \"skill_std\",\n",
    "    \"productive_receptive_ratio\"\n",
    "]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "X_scaled = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "\n",
    "# Preview scaled features\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d37e2",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split (with Categorical Encoding)\n",
    "\n",
    "In this step, we prepare the dataset for model training by ensuring the data is correctly split and all features are numerical.  \n",
    "\n",
    "**Process:**  \n",
    "1. **Split the dataset** into training and testing sets using stratified sampling to preserve the distribution of CEFR levels.  \n",
    "2. **Identify categorical engineered features**:  \n",
    "   - `strongest_skill`  \n",
    "   - `weakest_skill`  \n",
    "   - `second_weakest_skill`  \n",
    "   - `learning_profile`  \n",
    "3. **Encode categorical features** using **One-Hot Encoding (OHE)** to convert them into numerical dummy variables.  \n",
    "4. **Retain numeric features** (already scaled in Step 6) without further modification.  \n",
    "5. Combine the numeric and encoded categorical features to form the final training and test sets (`X_train_final`, `X_test_final`).  \n",
    "\n",
    "This ensures that the input dataset is fully numeric, consistent, and ready for use in the **Modeling & Evaluation notebook**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c7cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (before encoding): (803, 12)\n",
      "Test set shape (before encoding): (201, 12)\n",
      "Training set shape (after encoding): (803, 18)\n",
      "Test set shape (after encoding): (201, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaking_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>listening_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>skill_std</th>\n",
       "      <th>strength_weakness_gap</th>\n",
       "      <th>productive_receptive_ratio</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>strongest_skill_reading</th>\n",
       "      <th>strongest_skill_speaking</th>\n",
       "      <th>strongest_skill_writing</th>\n",
       "      <th>weakest_skill_reading</th>\n",
       "      <th>weakest_skill_speaking</th>\n",
       "      <th>weakest_skill_writing</th>\n",
       "      <th>second_weakest_skill_reading</th>\n",
       "      <th>second_weakest_skill_speaking</th>\n",
       "      <th>second_weakest_skill_writing</th>\n",
       "      <th>learning_profile_Uneven Development</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>6.683313</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>5.446712</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>3.304038</td>\n",
       "      <td>7</td>\n",
       "      <td>1.006579</td>\n",
       "      <td>76.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>4.787136</td>\n",
       "      <td>11</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>78.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>3.696846</td>\n",
       "      <td>8</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>66.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaking_score  reading_score  listening_score  writing_score  skill_std  \\\n",
       "575              32             40               27             25   6.683313   \n",
       "576              26             34               31             39   5.446712   \n",
       "914              80             74               78             73   3.304038   \n",
       "665              81             79               83             72   4.787136   \n",
       "632              65             72               64             65   3.696846   \n",
       "\n",
       "     strength_weakness_gap  productive_receptive_ratio  avg_score  \\\n",
       "575                     15                    0.850746      31.00   \n",
       "576                     13                    1.000000      32.50   \n",
       "914                      7                    1.006579      76.25   \n",
       "665                     11                    0.944444      78.75   \n",
       "632                      8                    0.955882      66.50   \n",
       "\n",
       "     strongest_skill_reading  strongest_skill_speaking  \\\n",
       "575                      1.0                       0.0   \n",
       "576                      0.0                       0.0   \n",
       "914                      0.0                       1.0   \n",
       "665                      0.0                       0.0   \n",
       "632                      1.0                       0.0   \n",
       "\n",
       "     strongest_skill_writing  weakest_skill_reading  weakest_skill_speaking  \\\n",
       "575                      0.0                    0.0                     0.0   \n",
       "576                      1.0                    0.0                     1.0   \n",
       "914                      0.0                    0.0                     0.0   \n",
       "665                      0.0                    0.0                     0.0   \n",
       "632                      0.0                    0.0                     0.0   \n",
       "\n",
       "     weakest_skill_writing  second_weakest_skill_reading  \\\n",
       "575                    1.0                           0.0   \n",
       "576                    0.0                           0.0   \n",
       "914                    1.0                           1.0   \n",
       "665                    1.0                           1.0   \n",
       "632                    0.0                           0.0   \n",
       "\n",
       "     second_weakest_skill_speaking  second_weakest_skill_writing  \\\n",
       "575                            0.0                           0.0   \n",
       "576                            0.0                           0.0   \n",
       "914                            0.0                           0.0   \n",
       "665                            0.0                           0.0   \n",
       "632                            1.0                           0.0   \n",
       "\n",
       "     learning_profile_Uneven Development  \n",
       "575                                  1.0  \n",
       "576                                  1.0  \n",
       "914                                  0.0  \n",
       "665                                  0.0  \n",
       "632                                  0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Train/Test Split with Categorical Encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define target\n",
    "y = df[\"cefr_encoded\"]\n",
    "\n",
    "# Features (drop raw CEFR columns)\n",
    "X = df.drop(columns=[\"overall_cefr\", \"cefr_encoded\"])\n",
    "\n",
    "# Train/Test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape (before encoding):\", X_train.shape)\n",
    "print(\"Test set shape (before encoding):\", X_test.shape)\n",
    "\n",
    "# ---- Handle Categorical Features ---- #\n",
    "categorical_features = [\"strongest_skill\", \"weakest_skill\", \"second_weakest_skill\", \"learning_profile\"]\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(drop=\"first\", sparse_output=False)  # drop=\"first\" avoids dummy trap\n",
    "\n",
    "# Fit on training set only (to avoid data leakage)\n",
    "X_train_cat = ohe.fit_transform(X_train[categorical_features])\n",
    "X_test_cat = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# Get feature names after encoding\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Convert to DataFrame\n",
    "import pandas as pd\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=ohe_feature_names, index=X_train.index)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=ohe_feature_names, index=X_test.index)\n",
    "\n",
    "# Drop original categorical columns and join encoded ones\n",
    "X_train_final = pd.concat([X_train.drop(columns=categorical_features), X_train_cat], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop(columns=categorical_features), X_test_cat], axis=1)\n",
    "\n",
    "print(\"Training set shape (after encoding):\", X_train_final.shape)\n",
    "print(\"Test set shape (after encoding):\", X_test_final.shape)\n",
    "\n",
    "# Quick check on final dataset\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a213938",
   "metadata": {},
   "source": [
    "## 4. Final Feature Set Overview  \n",
    "\n",
    "In this step, we will validate the final dataset before moving to the **Modelling & Evaluation** stage. Specifically, we will:  \n",
    "\n",
    "- Inspect the final **feature matrix (`X`)** and **target (`y`)**.  \n",
    "- Confirm the **dimensions** of the train/test splits after preprocessing.  \n",
    "- Preview the **transformed features** to check that both numerical (scaled) and categorical (one-hot encoded) variables are included.  \n",
    "- Verify that **stratified sampling** preserved the distribution of CEFR levels in both training and testing sets.\n",
    "\n",
    "This step ensures that the dataset is properly structured and balanced, which is essential for reliable model training and evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49ea408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (803, 12)\n",
      "X_test shape: (201, 12)\n",
      "y_train shape: (803,)\n",
      "y_test shape: (201,)\n",
      "\n",
      "Sample of transformed features (X_train):\n",
      "     speaking_score  reading_score  listening_score  writing_score  \\\n",
      "575              32             40               27             25   \n",
      "576              26             34               31             39   \n",
      "914              80             74               78             73   \n",
      "665              81             79               83             72   \n",
      "632              65             72               64             65   \n",
      "\n",
      "    strongest_skill weakest_skill second_weakest_skill  skill_std  \\\n",
      "575         reading       writing            listening   6.683313   \n",
      "576         writing      speaking            listening   5.446712   \n",
      "914        speaking       writing              reading   3.304038   \n",
      "665       listening       writing              reading   4.787136   \n",
      "632         reading     listening             speaking   3.696846   \n",
      "\n",
      "     strength_weakness_gap  productive_receptive_ratio  avg_score  \\\n",
      "575                     15                    0.850746      31.00   \n",
      "576                     13                    1.000000      32.50   \n",
      "914                      7                    1.006579      76.25   \n",
      "665                     11                    0.944444      78.75   \n",
      "632                      8                    0.955882      66.50   \n",
      "\n",
      "       learning_profile  \n",
      "575  Uneven Development  \n",
      "576  Uneven Development  \n",
      "914            Balanced  \n",
      "665            Balanced  \n",
      "632            Balanced  \n",
      "\n",
      "Target distribution (train): {np.int64(0): np.int64(166), np.int64(1): np.int64(175), np.int64(2): np.int64(166), np.int64(3): np.int64(154), np.int64(4): np.int64(75), np.int64(5): np.int64(67)}\n",
      "Target distribution (test): {np.int64(0): np.int64(42), np.int64(1): np.int64(44), np.int64(2): np.int64(42), np.int64(3): np.int64(38), np.int64(4): np.int64(19), np.int64(5): np.int64(16)}\n"
     ]
    }
   ],
   "source": [
    "# Check shapes of train/test splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Preview feature matrix (first 5 rows)\n",
    "print(\"\\nSample of transformed features (X_train):\")\n",
    "print(X_train[:5])\n",
    "\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_dist = dict(zip(unique, counts))\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_dist = dict(zip(unique, counts))\n",
    "\n",
    "print(\"\\nTarget distribution (train):\", train_dist)\n",
    "print(\"Target distribution (test):\", test_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216adc5",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
